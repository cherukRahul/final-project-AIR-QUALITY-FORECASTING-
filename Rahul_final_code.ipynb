{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherukRahul/final-project-AIR-QUALITY-FORECASTING-/blob/main/Rahul_final_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1️⃣ Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#  Load Dataset\n",
        "file_path = \"city_day.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "#  Basic Info\n",
        "print(\"✅ Data Loaded Successfully!\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(\"\\nColumns:\", df.columns.tolist())\n",
        "df.head()\n",
        "\n",
        "#  Data Summary\n",
        "print(\"\\nMissing Values per Column:\\n\", df.isnull().sum())\n",
        "print(\"\\nUnique Cities:\", df['City'].nunique())\n",
        "\n",
        "#  Convert Dates and Sort\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df = df.sort_values(by=['City', 'Date']).reset_index(drop=True)\n",
        "\n",
        "#  Handle Missing Values (Forward Fill by City)\n",
        "df = df.groupby('City').apply(lambda x: x.fillna(method='ffill')).reset_index(drop=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "8FGv_tAO99Dk",
        "outputId": "1ceb7cf7-3745-4621-9daa-68187b8a007d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'city_day.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1592052677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m#  Load Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"city_day.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#  Basic Info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'city_day.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Exploratory Data Analysis (EDA)\n",
        "\n",
        "# 3.1 Overview of the Dataset\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "\n",
        "# 3.2 Missing Values Check\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Print the first few columns (say, first 3 columns) for the first few rows\n",
        "print(df.iloc[:, :].head(10))"
      ],
      "metadata": {
        "id": "clVnb05M8AFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# AQI Trend Over Time (for one city)\n",
        "city = 'Delhi'\n",
        "city_df = df[df['City'] == city]\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(city_df['Date'], city_df['AQI'], color='teal', linewidth=2)\n",
        "plt.title(f'{city} - Air Quality Index (AQI) Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('AQI')\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Correlation Heatmap (Air Pollutants vs AQI)\n",
        "\n",
        "cols = ['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene', 'AQI']\n",
        "corr = df[cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Heatmap of Pollutants and AQI')\n",
        "plt.show()\n",
        "\n",
        "#AQI Distribution (Histogram + KDE)\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(df['AQI'], bins=40, kde=True, color='skyblue')\n",
        "plt.title('Distribution of AQI Across All Cities')\n",
        "plt.xlabel('AQI')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#Comparison of AQI Levels Across Major Cities (Box Plot)\n",
        "major_cities = ['Delhi', 'Mumbai', 'Kolkata', 'Chennai', 'Bengaluru', 'Hyderabad']\n",
        "subset = df[df['City'].isin(major_cities)]\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.boxplot(data=subset, x='City', y='AQI', palette='Set2')\n",
        "plt.title('AQI Distribution Across Major Cities')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gVdem6e2-Lee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====================================================\n",
        "#       AIR QUALITY FORECASTING MODELS\n",
        "#   ARIMA • SARIMA • RANDOM FOREST • XGBOOST • LSTM\n",
        "# ====================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train/test split\n",
        "train = city_df.iloc[:-100]\n",
        "test = city_df.iloc[-100:]\n",
        "\n",
        "# =====================================================================\n",
        "#                          ARIMA MODEL\n",
        "# =====================================================================\n",
        "\n",
        "\n",
        "# Use only numeric AQI series\n",
        "train_aqi = train[\"AQI\"]\n",
        "test_aqi = test[\"AQI\"]\n",
        "\n",
        "# Fit ARIMA model\n",
        "arima_model = ARIMA(train_aqi, order=(5,1,2))\n",
        "arima_fit = arima_model.fit()\n",
        "\n",
        "# Forecast (with integer index—this is OK)\n",
        "arima_pred = arima_fit.forecast(steps=len(test_aqi))\n",
        "\n",
        "# Convert predictions to numpy array (important)\n",
        "arima_pred = np.array(arima_pred)\n",
        "\n",
        "# Compute metrics\n",
        "rmse_arima = np.sqrt(mean_squared_error(test_aqi.values, arima_pred))\n",
        "mae_arima = mean_absolute_error(test_aqi.values, arima_pred)\n",
        "\n",
        "print(f\"ARIMA RMSE: {rmse_arima:.2f}\")\n",
        "print(f\"ARIMA MAE : {mae_arima:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index, test[\"AQI\"], label=\"Actual AQI\")\n",
        "plt.plot(test.index, arima_pred, label=\"ARIMA Prediction\")\n",
        "plt.legend()\n",
        "plt.title(\"ARIMA Forecast\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bNuhtU4mz6W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "#                          SARIMA MODEL\n",
        "# =====================================================================\n",
        "\n",
        "# Use only numeric AQI series\n",
        "train_aqi = train[\"AQI\"]\n",
        "test_aqi = test[\"AQI\"]\n",
        "\n",
        "# Fit SARIMA model\n",
        "sarima_model = SARIMAX(train_aqi, order=(3,1,2), seasonal_order=(2,1,1,12))\n",
        "sarima_fit = sarima_model.fit()\n",
        "\n",
        "# Forecast\n",
        "sarima_pred = sarima_fit.forecast(steps=len(test_aqi))\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "sarima_pred = np.array(sarima_pred)\n",
        "\n",
        "# Compute metrics\n",
        "rmse_sarima = np.sqrt(mean_squared_error(test_aqi.values, sarima_pred))\n",
        "mae_sarima = mean_absolute_error(test_aqi.values, sarima_pred)\n",
        "\n",
        "print(f\"SARIMA RMSE: {rmse_sarima:.2f}\")\n",
        "print(f\"SARIMA MAE : {mae_sarima:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index, test[\"AQI\"], label=\"Actual AQI\")\n",
        "plt.plot(test.index, sarima_pred, label=\"SARIMA Prediction\")\n",
        "plt.legend()\n",
        "plt.title(\"SARIMA Forecast\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pYOeW6hq20Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =====================================================================\n",
        "#                      RANDOM FOREST REGRESSOR\n",
        "# =====================================================================\n",
        "print(\"\\n================ RANDOM FOREST (FIXED) ================\\n\")\n",
        "\n",
        "# Create lag features\n",
        "def create_lags(df, lag=7):\n",
        "    df = df.copy()\n",
        "    for i in range(1, lag+1):\n",
        "        df[f\"lag_{i}\"] = df[\"AQI\"].shift(i)\n",
        "    return df.dropna()\n",
        "\n",
        "# Only keep AQI column before creating lags\n",
        "aqi_only_df = city_df[[\"AQI\"]]\n",
        "\n",
        "lag_df = create_lags(aqi_only_df, lag=7)\n",
        "\n",
        "# Input features (all lag columns)\n",
        "X = lag_df.drop(\"AQI\", axis=1)\n",
        "\n",
        "# Target\n",
        "y = lag_df[\"AQI\"]\n",
        "\n",
        "# Split using same 100-step rule\n",
        "X_train = X.iloc[:-100]\n",
        "X_test  = X.iloc[-100:]\n",
        "y_train = y.iloc[:-100]\n",
        "y_test  = y.iloc[-100:]\n",
        "\n",
        "# Train model\n",
        "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "rf_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "rmse_rf = np.sqrt(mean_squared_error(y_test, rf_pred))\n",
        "mae_rf  = mean_absolute_error(y_test, rf_pred)\n",
        "\n",
        "print(f\"Random Forest RMSE: {rmse_rf:.2f}\")\n",
        "print(f\"Random Forest MAE : {mae_rf:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index, test[\"AQI\"], label=\"Actual AQI\")\n",
        "plt.plot(test.index, rf_pred, label=\"Random Forest Prediction\")\n",
        "plt.legend()\n",
        "plt.title(\"Random Forest Forecast\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lx-why8i3KDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================================================\n",
        "#                            XGBOOST\n",
        "# =====================================================================\n",
        "print(\"\\n================ XGBOOST ================\\n\")\n",
        "\n",
        "xgb = XGBRegressor(n_estimators=300, learning_rate=0.05, max_depth=5)\n",
        "xgb.fit(X_train, y_train)\n",
        "xgb_pred = xgb.predict(X_test)\n",
        "\n",
        "rmse_xgb = np.sqrt(mean_squared_error(y_test, xgb_pred))\n",
        "mae_xgb = mean_absolute_error(y_test, xgb_pred)\n",
        "\n",
        "print(f\"XGBoost RMSE: {rmse_xgb:.2f}\")\n",
        "print(f\"XGBoost MAE : {mae_xgb:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index, test[\"AQI\"], label=\"Actual AQI\")\n",
        "plt.plot(test.index, xgb_pred, label=\"XGBoost Prediction\")\n",
        "plt.legend()\n",
        "plt.title(\"XGBoost Forecast\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "CF5qy3al3hRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n================ LSTM MODEL (FIXED) ================\\n\")\n",
        "\n",
        "# Use only AQI values (numeric)\n",
        "aqi_series = city_df[\"AQI\"].values.reshape(-1, 1)\n",
        "\n",
        "# Scale only numeric AQI\n",
        "scaler = StandardScaler()\n",
        "scaled_aqi = scaler.fit_transform(aqi_series)\n",
        "\n",
        "# LSTM sequence length\n",
        "seq_len = 7\n",
        "\n",
        "# Create generator\n",
        "generator = TimeseriesGenerator(\n",
        "    scaled_aqi, scaled_aqi,\n",
        "    length=seq_len,\n",
        "    batch_size=16\n",
        ")\n",
        "\n",
        "# Build LSTM model\n",
        "lstm_model = Sequential([\n",
        "    LSTM(64, activation=\"relu\", input_shape=(seq_len, 1)),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "lstm_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "lstm_model.fit(generator, epochs=10, verbose=1)\n",
        "\n",
        "# ---- Forecast last 100 steps ---- #\n",
        "lstm_preds = []\n",
        "test_scaled = scaled_aqi[-(100 + seq_len):]\n",
        "\n",
        "for i in range(100):\n",
        "    sample = test_scaled[i:i+seq_len].reshape(1, seq_len, 1)\n",
        "    pred = lstm_model.predict(sample, verbose=0)\n",
        "    lstm_preds.append(pred[0][0])\n",
        "\n",
        "# Inverse transform predictions\n",
        "lstm_preds = scaler.inverse_transform(np.array(lstm_preds).reshape(-1, 1))\n",
        "\n",
        "# True values (numeric only)\n",
        "true_values = city_df[\"AQI\"].iloc[-100:].values\n",
        "\n",
        "# Metrics\n",
        "rmse_lstm = np.sqrt(mean_squared_error(true_values, lstm_preds))\n",
        "mae_lstm  = mean_absolute_error(true_values, lstm_preds)\n",
        "\n",
        "print(f\"LSTM RMSE : {rmse_lstm:.2f}\")\n",
        "print(f\"LSTM MAE  : {mae_lstm:.2f}\")\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index, test[\"AQI\"], label=\"Actual AQI\")\n",
        "plt.plot(test.index, lstm_preds, label=\"LSTM Prediction\")\n",
        "plt.legend()\n",
        "plt.title(\"LSTM Forecast\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "NK28mqLD2J4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# =====================================================================\n",
        "#                        COMPARISON PLOT\n",
        "# =====================================================================\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(test.index, test[\"AQI\"], label=\"Actual AQI\", linewidth=2)\n",
        "plt.plot(test.index, arima_pred, label=\"ARIMA\")\n",
        "plt.plot(test.index, sarima_pred, label=\"SARIMA\")\n",
        "plt.plot(test.index, rf_pred, label=\"Random Forest\")\n",
        "plt.plot(test.index, xgb_pred, label=\"XGBoost\")\n",
        "plt.plot(test.index, lstm_preds, label=\"LSTM\")\n",
        "plt.legend()\n",
        "plt.title(\"Model Comparison — AQI Forecasting\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZO7Ek2Lw2Uqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "param_grid_rf = {\n",
        "    \"n_estimators\": [100, 200, 300],\n",
        "    \"max_depth\": [5, 10, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    rf,\n",
        "    param_grid_rf,\n",
        "    cv=3,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid_rf.best_params_)\n",
        "print(\"Best RMSE:\", (-grid_rf.best_score_)**0.5)\n"
      ],
      "metadata": {
        "id": "bztfv8RQCwg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist_xgb = {\n",
        "    \"n_estimators\": [200, 300, 500],\n",
        "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
        "    \"max_depth\": [3, 5, 7],\n",
        "    \"subsample\": [0.7, 0.8, 1.0],\n",
        "    \"colsample_bytree\": [0.7, 0.8, 1.0],\n",
        "    \"gamma\": [0, 1, 5]\n",
        "}\n",
        "\n",
        "xgb = XGBRegressor(random_state=42, eval_metric='rmse')\n",
        "\n",
        "random_xgb = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist_xgb,\n",
        "    n_iter=20,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=2,\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "\n",
        "random_xgb.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", random_xgb.best_params_)\n",
        "print(\"Best RMSE:\", (-random_xgb.best_score_)**0.5)\n"
      ],
      "metadata": {
        "id": "SvKH8C4TCzvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pmdarima import auto_arima\n",
        "\n",
        "auto_arima_model = auto_arima(\n",
        "    train[\"AQI\"],\n",
        "    seasonal=False,\n",
        "    trace=True,\n",
        "    error_action=\"ignore\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True\n",
        ")\n",
        "\n",
        "print(auto_arima_model.summary())\n"
      ],
      "metadata": {
        "id": "OcXCl4FIC25_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_sarima_model = auto_arima(\n",
        "    train[\"AQI\"],\n",
        "    seasonal=True,\n",
        "    m=12,\n",
        "    trace=True,\n",
        "    error_action=\"ignore\",\n",
        "    suppress_warnings=True,\n",
        "    stepwise=True\n",
        ")\n",
        "\n",
        "print(auto_sarima_model.summary())\n"
      ],
      "metadata": {
        "id": "VCz_BcDZC6eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "def build_lstm(hp):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        units=hp.Int(\"units\", min_value=32, max_value=128, step=32),\n",
        "        activation=\"relu\",\n",
        "        input_shape=(seq_len, 1)\n",
        "    ))\n",
        "    model.add(Dense(1))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"mse\"\n",
        "    )\n",
        "    return model\n",
        "\n",
        "tuner = kt.RandomSearch(\n",
        "    build_lstm,\n",
        "    objective=\"val_loss\",\n",
        "    max_trials=5,\n",
        "    directory=\"lstm_tuning\",\n",
        "    project_name=\"aqi_lstm\"\n",
        ")\n",
        "\n",
        "tuner.search(X_train_lstm, y_train_lstm, epochs=10, validation_split=0.2)\n",
        "best_lstm = tuner.get_best_models(num_models=1)[0]\n",
        "best_lstm.summary()\n"
      ],
      "metadata": {
        "id": "FZb7kpqIC-Ey"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}